{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Predicting dermatological diseases </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this application we are going to use the [Dermatology Data Set](https://archive.ics.uci.edu/ml/datasets/dermatology) from <b> UCI Machine Learning Repository</b>. It provides us 12 clinical attributes and 22 histopathological attributes related to 6 different diseases: <br>\n",
    "\n",
    "1. Psoriasis\n",
    "2. Seboreic dermatitis\n",
    "3. Lichen planus\n",
    "4. Pityriasis rosea\n",
    "5. Cronic dermatitis\n",
    "6. Pityriasis rubra pilaris\n",
    "<br>\n",
    "\n",
    "Our _goal_ is to <b> classify which disease the patient has based on these attributes</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Preprocessing </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For preprocessing our data set, we could change it for the one-hot-enconding approach. Since there is a lot of examples of that on the internet, we are going to try the multiclassification approach with integer values as our targets (diseases 1 to 6). <br>\n",
    "\n",
    "Another thing here is since some algorithms cannot deal with missing values (NaN), we decided to delete these rows.\n",
    "<br>\n",
    "\n",
    "Ps.: we manually put the names of the attributes in the .csv file, but it can be done by code as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = pd.read_csv(\"Dermatology.csv\", na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_dataset.dropna()\n",
    "dataset.reset_index(drop=True, inplace=True) #reorder rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>erythema</th>\n",
       "      <th>scaling</th>\n",
       "      <th>definiteBorders</th>\n",
       "      <th>itching</th>\n",
       "      <th>koebnerPhenomenon</th>\n",
       "      <th>polygonalPapules</th>\n",
       "      <th>follicularPapules</th>\n",
       "      <th>oralMucosal</th>\n",
       "      <th>kneeElbow</th>\n",
       "      <th>scalp</th>\n",
       "      <th>...</th>\n",
       "      <th>disappearance</th>\n",
       "      <th>vacuolisation</th>\n",
       "      <th>spongiosis</th>\n",
       "      <th>sawTooth</th>\n",
       "      <th>follicularPlug</th>\n",
       "      <th>perifollicular</th>\n",
       "      <th>mononuclear</th>\n",
       "      <th>bandLike</th>\n",
       "      <th>age</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     erythema  scaling  definiteBorders  itching  koebnerPhenomenon  \\\n",
       "353         2        1                1        0                  1   \n",
       "354         3        2                1        0                  1   \n",
       "355         3        2                2        2                  3   \n",
       "356         2        1                3        1                  2   \n",
       "357         3        2                2        0                  0   \n",
       "\n",
       "     polygonalPapules  follicularPapules  oralMucosal  kneeElbow  scalp  ...  \\\n",
       "353                 0                  0            0          0      0  ...   \n",
       "354                 0                  0            0          0      0  ...   \n",
       "355                 2                  0            2          0      0  ...   \n",
       "356                 3                  0            2          0      0  ...   \n",
       "357                 0                  0            0          3      3  ...   \n",
       "\n",
       "     disappearance  vacuolisation  spongiosis  sawTooth  follicularPlug  \\\n",
       "353              0              0           1         0               0   \n",
       "354              1              0           1         0               0   \n",
       "355              0              3           0         3               0   \n",
       "356              0              2           0         1               0   \n",
       "357              2              0           0         0               0   \n",
       "\n",
       "     perifollicular  mononuclear  bandLike   age  disease  \n",
       "353               0            2         0  25.0        4  \n",
       "354               0            2         0  36.0        4  \n",
       "355               0            2         3  28.0        3  \n",
       "356               0            2         3  50.0        3  \n",
       "357               0            3         0  35.0        1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail() #if you want to print everything, just type 'dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Separating the data set </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __future__ #for future features in newer versions\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.75,random_state=0) #the random_state gives the seed for the randomization \n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The label is the value we want to predict (in this case, we want to predict the disease): </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.pop('disease')\n",
    "test_labels = test_dataset.pop('disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Artificial Neural Network </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For building our ANN we used some _rules-of-thumb_ presented in [this](https://towardsdatascience.com/17-rules-of-thumb-for-building-a-neural-network-93356f9930a) article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember: 34 features + 1 (disease)\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(len(train_dataset.keys())), #input_shape = 34\n",
    "        layers.Dense(16, activation = 'relu'),\n",
    "        layers.Dense(8, activation = 'relu'),\n",
    "        layers.Dense(7, activation = 'softmax'), #6 possible diseases\n",
    "    ])\n",
    "\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['acc']) \n",
    "    #sparse is used here because our target values are not one-hot-encoded, but integers\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0917 14:37:06.242386  2156 deprecation.py:506] From C:\\Users\\amand\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                560       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 63        \n",
      "=================================================================\n",
      "Total params: 759\n",
      "Trainable params: 759\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "print(model.summary())\n",
    "\n",
    "#params = current *(previous +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Now we have to see if the model training shows decreasing loss and any improvement in accuracy (acc): </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/85\n",
      "268/268 [==============================] - 2s 6ms/sample - loss: 2.1855 - acc: 0.3806\n",
      "Epoch 2/85\n",
      "268/268 [==============================] - 0s 179us/sample - loss: 1.7345 - acc: 0.4888\n",
      "Epoch 3/85\n",
      "268/268 [==============================] - 0s 224us/sample - loss: 1.5378 - acc: 0.4963\n",
      "Epoch 4/85\n",
      "268/268 [==============================] - 0s 194us/sample - loss: 1.3938 - acc: 0.4963\n",
      "Epoch 5/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 1.3004 - acc: 0.4963\n",
      "Epoch 6/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 1.2245 - acc: 0.5149\n",
      "Epoch 7/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 1.1564 - acc: 0.5299\n",
      "Epoch 8/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 1.0993 - acc: 0.5522\n",
      "Epoch 9/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 1.0482 - acc: 0.5597\n",
      "Epoch 10/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 1.0072 - acc: 0.5672\n",
      "Epoch 11/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.9576 - acc: 0.5933\n",
      "Epoch 12/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.9163 - acc: 0.6231\n",
      "Epoch 13/85\n",
      "268/268 [==============================] - 0s 105us/sample - loss: 0.8646 - acc: 0.6455\n",
      "Epoch 14/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.8243 - acc: 0.6381\n",
      "Epoch 15/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.7903 - acc: 0.7052\n",
      "Epoch 16/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.7627 - acc: 0.7425\n",
      "Epoch 17/85\n",
      "268/268 [==============================] - 0s 119us/sample - loss: 0.7308 - acc: 0.7351\n",
      "Epoch 18/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.7015 - acc: 0.7500\n",
      "Epoch 19/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.6719 - acc: 0.7687\n",
      "Epoch 20/85\n",
      "268/268 [==============================] - 0s 89us/sample - loss: 0.6433 - acc: 0.7761\n",
      "Epoch 21/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.6159 - acc: 0.7836\n",
      "Epoch 22/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.5889 - acc: 0.7687\n",
      "Epoch 23/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.5637 - acc: 0.7836\n",
      "Epoch 24/85\n",
      "268/268 [==============================] - 0s 119us/sample - loss: 0.5418 - acc: 0.7873\n",
      "Epoch 25/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.5206 - acc: 0.7873\n",
      "Epoch 26/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.4998 - acc: 0.8022\n",
      "Epoch 27/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.4817 - acc: 0.8097\n",
      "Epoch 28/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.4648 - acc: 0.8209\n",
      "Epoch 29/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.4485 - acc: 0.8246\n",
      "Epoch 30/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.4336 - acc: 0.8172\n",
      "Epoch 31/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.4190 - acc: 0.8321\n",
      "Epoch 32/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.4055 - acc: 0.8470\n",
      "Epoch 33/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.3935 - acc: 0.8545\n",
      "Epoch 34/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.3813 - acc: 0.8694\n",
      "Epoch 35/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.3697 - acc: 0.8731\n",
      "Epoch 36/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.3587 - acc: 0.8843\n",
      "Epoch 37/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.3484 - acc: 0.8918\n",
      "Epoch 38/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.3390 - acc: 0.9067\n",
      "Epoch 39/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.3278 - acc: 0.9179\n",
      "Epoch 40/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.3180 - acc: 0.9328\n",
      "Epoch 41/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.3093 - acc: 0.9291\n",
      "Epoch 42/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.2993 - acc: 0.9366\n",
      "Epoch 43/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.2902 - acc: 0.9478\n",
      "Epoch 44/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.2827 - acc: 0.9478\n",
      "Epoch 45/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.2721 - acc: 0.9552\n",
      "Epoch 46/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.2677 - acc: 0.9515\n",
      "Epoch 47/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.2542 - acc: 0.9552\n",
      "Epoch 48/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.2484 - acc: 0.9590\n",
      "Epoch 49/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.2404 - acc: 0.9627\n",
      "Epoch 50/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.2317 - acc: 0.9552\n",
      "Epoch 51/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.2238 - acc: 0.9552\n",
      "Epoch 52/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.2165 - acc: 0.9515\n",
      "Epoch 53/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.2093 - acc: 0.9590\n",
      "Epoch 54/85\n",
      "268/268 [==============================] - 0s 89us/sample - loss: 0.2032 - acc: 0.9627\n",
      "Epoch 55/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.1960 - acc: 0.9627\n",
      "Epoch 56/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1917 - acc: 0.9627\n",
      "Epoch 57/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1864 - acc: 0.9664\n",
      "Epoch 58/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1811 - acc: 0.9664\n",
      "Epoch 59/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.1761 - acc: 0.9627\n",
      "Epoch 60/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.1718 - acc: 0.9701\n",
      "Epoch 61/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1657 - acc: 0.9739\n",
      "Epoch 62/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.1634 - acc: 0.9590\n",
      "Epoch 63/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.1581 - acc: 0.9664\n",
      "Epoch 64/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1540 - acc: 0.9664\n",
      "Epoch 65/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.1497 - acc: 0.9664\n",
      "Epoch 66/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1459 - acc: 0.9627\n",
      "Epoch 67/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1421 - acc: 0.9664\n",
      "Epoch 68/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.1389 - acc: 0.9701\n",
      "Epoch 69/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.1359 - acc: 0.9739\n",
      "Epoch 70/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1284 - acc: 0.9627\n",
      "Epoch 71/85\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.1132 - acc: 0.968 - 0s 60us/sample - loss: 0.1233 - acc: 0.9664\n",
      "Epoch 72/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.1182 - acc: 0.9701\n",
      "Epoch 73/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1150 - acc: 0.9739\n",
      "Epoch 74/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1128 - acc: 0.9739\n",
      "Epoch 75/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1104 - acc: 0.9590\n",
      "Epoch 76/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1039 - acc: 0.9664\n",
      "Epoch 77/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1021 - acc: 0.9776\n",
      "Epoch 78/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1011 - acc: 0.9776\n",
      "Epoch 79/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.0962 - acc: 0.9739\n",
      "Epoch 80/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.0955 - acc: 0.9664\n",
      "Epoch 81/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0909 - acc: 0.9701\n",
      "Epoch 82/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.0902 - acc: 0.9776\n",
      "Epoch 83/85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0876 - acc: 0.9701\n",
      "Epoch 84/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0851 - acc: 0.9739\n",
      "Epoch 85/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.0845 - acc: 0.9776\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_ANN = model.fit(train_dataset, train_labels, epochs=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.plot(predicted_labels_ANN.history['acc'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 269us/sample - loss: 0.0816 - acc: 0.9739\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(train_dataset, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 89us/sample - loss: 0.1164 - acc: 0.9667\n"
     ]
    }
   ],
   "source": [
    "final_results = model.evaluate(test_dataset, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Naive Bayes </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Let's test the Gaussian Naive Bayes approach: </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "modelB = GaussianNB().fit(train_dataset, train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = modelB.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score = accuracy_score(test_labels, predicted_label) \n",
    "print (accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Metrics </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function to display dataframes for a better analysis. For more details see [here](https://stackoverflow.com/questions/38783027/jupyter-notebook-display-two-pandas-tables-side-by-side)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def display_side_by_side(dfs:list, captions:list):\n",
    "    \"\"\"Display tables side by side to save vertical space\n",
    "    Input:\n",
    "        dfs: list of pandas.DataFrame\n",
    "        captions: list of table captions\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    combined = dict(zip(captions, dfs))\n",
    "    for caption, df in combined.items():\n",
    "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += \"\\xa0\\xa0\\xa0\"\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_cf663a82_d971_11e9_97c9_a402b9003abb\" style='display:inline'><caption>ANN</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >1</th>        <th class=\"col_heading level0 col1\" >2</th>        <th class=\"col_heading level0 col2\" >3</th>        <th class=\"col_heading level0 col3\" >4</th>        <th class=\"col_heading level0 col4\" >5</th>        <th class=\"col_heading level0 col5\" >6</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_cf663a82_d971_11e9_97c9_a402b9003abblevel0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow0_col0\" class=\"data row0 col0\" >35</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow0_col1\" class=\"data row0 col1\" >1</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow0_col2\" class=\"data row0 col2\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow0_col3\" class=\"data row0 col3\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow0_col4\" class=\"data row0 col4\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow0_col5\" class=\"data row0 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cf663a82_d971_11e9_97c9_a402b9003abblevel0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow1_col0\" class=\"data row1 col0\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow1_col1\" class=\"data row1 col1\" >11</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow1_col2\" class=\"data row1 col2\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow1_col3\" class=\"data row1 col3\" >1</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow1_col4\" class=\"data row1 col4\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow1_col5\" class=\"data row1 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cf663a82_d971_11e9_97c9_a402b9003abblevel0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow2_col0\" class=\"data row2 col0\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow2_col1\" class=\"data row2 col1\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow2_col2\" class=\"data row2 col2\" >14</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow2_col3\" class=\"data row2 col3\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow2_col4\" class=\"data row2 col4\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow2_col5\" class=\"data row2 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cf663a82_d971_11e9_97c9_a402b9003abblevel0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow3_col0\" class=\"data row3 col0\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow3_col1\" class=\"data row3 col1\" >1</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow3_col2\" class=\"data row3 col2\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow3_col3\" class=\"data row3 col3\" >13</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow3_col4\" class=\"data row3 col4\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow3_col5\" class=\"data row3 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cf663a82_d971_11e9_97c9_a402b9003abblevel0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow4_col0\" class=\"data row4 col0\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow4_col1\" class=\"data row4 col1\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow4_col2\" class=\"data row4 col2\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow4_col3\" class=\"data row4 col3\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow4_col4\" class=\"data row4 col4\" >12</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow4_col5\" class=\"data row4 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cf663a82_d971_11e9_97c9_a402b9003abblevel0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow5_col0\" class=\"data row5 col0\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow5_col1\" class=\"data row5 col1\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow5_col2\" class=\"data row5 col2\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow5_col3\" class=\"data row5 col3\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow5_col4\" class=\"data row5 col4\" >0</td>\n",
       "                        <td id=\"T_cf663a82_d971_11e9_97c9_a402b9003abbrow5_col5\" class=\"data row5 col5\" >2</td>\n",
       "            </tr>\n",
       "    </tbody></table>Â Â Â <style  type=\"text/css\" >\n",
       "</style><table id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abb\" style='display:inline'><caption>GNB</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >1</th>        <th class=\"col_heading level0 col1\" >2</th>        <th class=\"col_heading level0 col2\" >3</th>        <th class=\"col_heading level0 col3\" >4</th>        <th class=\"col_heading level0 col4\" >5</th>        <th class=\"col_heading level0 col5\" >6</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abblevel0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow0_col0\" class=\"data row0 col0\" >36</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow0_col1\" class=\"data row0 col1\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow0_col2\" class=\"data row0 col2\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow0_col3\" class=\"data row0 col3\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow0_col4\" class=\"data row0 col4\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow0_col5\" class=\"data row0 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abblevel0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow1_col0\" class=\"data row1 col0\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow1_col1\" class=\"data row1 col1\" >5</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow1_col2\" class=\"data row1 col2\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow1_col3\" class=\"data row1 col3\" >6</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow1_col4\" class=\"data row1 col4\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow1_col5\" class=\"data row1 col5\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abblevel0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow2_col0\" class=\"data row2 col0\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow2_col1\" class=\"data row2 col1\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow2_col2\" class=\"data row2 col2\" >14</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow2_col3\" class=\"data row2 col3\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow2_col4\" class=\"data row2 col4\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow2_col5\" class=\"data row2 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abblevel0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow3_col0\" class=\"data row3 col0\" >1</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow3_col1\" class=\"data row3 col1\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow3_col2\" class=\"data row3 col2\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow3_col3\" class=\"data row3 col3\" >13</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow3_col4\" class=\"data row3 col4\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow3_col5\" class=\"data row3 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abblevel0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow4_col0\" class=\"data row4 col0\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow4_col1\" class=\"data row4 col1\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow4_col2\" class=\"data row4 col2\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow4_col3\" class=\"data row4 col3\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow4_col4\" class=\"data row4 col4\" >12</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow4_col5\" class=\"data row4 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abblevel0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow5_col0\" class=\"data row5 col0\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow5_col1\" class=\"data row5 col1\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow5_col2\" class=\"data row5 col2\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow5_col3\" class=\"data row5 col3\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow5_col4\" class=\"data row5 col4\" >0</td>\n",
       "                        <td id=\"T_cf66d6ae_d971_11e9_9a7d_a402b9003abbrow5_col5\" class=\"data row5 col5\" >2</td>\n",
       "            </tr>\n",
       "    </tbody></table>Â Â Â "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction_ANN = model.predict(test_dataset) #shows the probabilities for each disease given one row\n",
    "predictions_ANN = np.argmax(prediction_ANN, axis = 1) #the highest probability value is taken by the disease for that row\n",
    "\n",
    "labels = list(set(test_labels))\n",
    "df_ANN = pd.DataFrame(\n",
    "    data = confusion_matrix(test_labels, predictions_ANN, labels=labels),\n",
    "    columns=labels,\n",
    "    index=labels\n",
    ")\n",
    "\n",
    "\n",
    "df_GNB = pd.DataFrame(\n",
    "    data  = confusion_matrix(test_labels, predicted_label, labels=labels),\n",
    "    columns=labels,\n",
    "    index=labels\n",
    ")\n",
    "\n",
    "display_side_by_side([df_ANN, df_GNB], ['ANN', 'GNB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we present the metrics associated to the confusion matrix, let's do some recap about them. <br>\n",
    "\n",
    " - **Accuracy**: How often is the classifier correct?\n",
    " - **Precision**: Of those it classified correctly, how many were they?\n",
    " - **Recall**: When it belongs to some X class, how often it classifies as X?\n",
    " - **F1-score**: General quality (combines precision and recall). The higher the score, the better the model.\n",
    " <br>\n",
    "\n",
    "The more rigorous we are to predict correctly (improve precision) the less we are willing to make mistakes (increase recall).\n",
    "<br>\n",
    " \n",
    "Formulas: <br>\n",
    " - **Accuracy**: $\\frac{TP + TN}{total}$\n",
    " - **Precision**: $\\frac{TP}{TP+FP}$\n",
    " - **Recall**: $\\frac{TP}{TP+FN}$\n",
    " - **F1-score**:  $\\frac{2 * precision * recall}{precision + recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     1.0000    0.9722    0.9859        36\n",
      "           2     0.8462    0.9167    0.8800        12\n",
      "           3     1.0000    1.0000    1.0000        14\n",
      "           4     0.9286    0.9286    0.9286        14\n",
      "           5     1.0000    1.0000    1.0000        12\n",
      "           6     1.0000    1.0000    1.0000         2\n",
      "\n",
      "    accuracy                         0.9667        90\n",
      "   macro avg     0.9625    0.9696    0.9657        90\n",
      "weighted avg     0.9684    0.9667    0.9673        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9730    1.0000    0.9863        36\n",
      "           2     1.0000    0.4167    0.5882        12\n",
      "           3     1.0000    1.0000    1.0000        14\n",
      "           4     0.6842    0.9286    0.7879        14\n",
      "           5     1.0000    1.0000    1.0000        12\n",
      "           6     0.6667    1.0000    0.8000         2\n",
      "\n",
      "    accuracy                         0.9111        90\n",
      "   macro avg     0.8873    0.8909    0.8604        90\n",
      "weighted avg     0.9327    0.9111    0.9022        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, predictions_ANN, digits=4))\n",
    "print(classification_report(test_labels, predicted_label, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
