{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Preprocessing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = pd.read_csv(\"Dermatology.csv\", na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_dataset.dropna()\n",
    "dataset.reset_index(drop=True, inplace=True) #reorder rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>erythema</th>\n",
       "      <th>scaling</th>\n",
       "      <th>definiteBorders</th>\n",
       "      <th>itching</th>\n",
       "      <th>koebnerPhenomenon</th>\n",
       "      <th>polygonalPapules</th>\n",
       "      <th>follicularPapules</th>\n",
       "      <th>oralMucosal</th>\n",
       "      <th>kneeElbow</th>\n",
       "      <th>scalp</th>\n",
       "      <th>...</th>\n",
       "      <th>disappearance</th>\n",
       "      <th>vacuolisation</th>\n",
       "      <th>spongiosis</th>\n",
       "      <th>sawTooth</th>\n",
       "      <th>follicularPlug</th>\n",
       "      <th>perifollicular</th>\n",
       "      <th>mononuclear</th>\n",
       "      <th>bandLike</th>\n",
       "      <th>age</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     erythema  scaling  definiteBorders  itching  koebnerPhenomenon  \\\n",
       "353         2        1                1        0                  1   \n",
       "354         3        2                1        0                  1   \n",
       "355         3        2                2        2                  3   \n",
       "356         2        1                3        1                  2   \n",
       "357         3        2                2        0                  0   \n",
       "\n",
       "     polygonalPapules  follicularPapules  oralMucosal  kneeElbow  scalp  ...  \\\n",
       "353                 0                  0            0          0      0  ...   \n",
       "354                 0                  0            0          0      0  ...   \n",
       "355                 2                  0            2          0      0  ...   \n",
       "356                 3                  0            2          0      0  ...   \n",
       "357                 0                  0            0          3      3  ...   \n",
       "\n",
       "     disappearance  vacuolisation  spongiosis  sawTooth  follicularPlug  \\\n",
       "353              0              0           1         0               0   \n",
       "354              1              0           1         0               0   \n",
       "355              0              3           0         3               0   \n",
       "356              0              2           0         1               0   \n",
       "357              2              0           0         0               0   \n",
       "\n",
       "     perifollicular  mononuclear  bandLike   age  disease  \n",
       "353               0            2         0  25.0        4  \n",
       "354               0            2         0  36.0        4  \n",
       "355               0            2         3  28.0        3  \n",
       "356               0            2         3  50.0        3  \n",
       "357               0            3         0  35.0        1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail() #if you want to print everything, just type 'dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Artificial Neural Network </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __future__ #for future features in newer versions\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.75,random_state=0) #that's the seed for the randomization \n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The label is the value we want to predict (in this case, we want to predict the disease): </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.pop('disease')\n",
    "test_labels = test_dataset.pop('disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#34 features + 1 (disease)\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(len(train_dataset.keys())), #input_shape = 34\n",
    "        layers.Dense(16, activation = 'relu'),\n",
    "        layers.Dense(8, activation = 'relu'),\n",
    "        layers.Dense(7, activation = 'softmax'), #6 possible diseases\n",
    "    ])\n",
    "\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 16)                576       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 7)                 63        \n",
      "=================================================================\n",
      "Total params: 775\n",
      "Trainable params: 775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Now we have to see if the model training shows decreasing loss and any improvement in accuracy (acc): </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/85\n",
      "268/268 [==============================] - 1s 2ms/sample - loss: 12.5907 - acc: 0.0261\n",
      "Epoch 2/85\n",
      "268/268 [==============================] - 0s 194us/sample - loss: 9.7675 - acc: 0.0187\n",
      "Epoch 3/85\n",
      "268/268 [==============================] - 0s 194us/sample - loss: 7.5806 - acc: 0.0410\n",
      "Epoch 4/85\n",
      "268/268 [==============================] - 0s 224us/sample - loss: 5.7874 - acc: 0.0261\n",
      "Epoch 5/85\n",
      "268/268 [==============================] - 0s 269us/sample - loss: 4.4887 - acc: 0.0448\n",
      "Epoch 6/85\n",
      "268/268 [==============================] - 0s 284us/sample - loss: 3.5405 - acc: 0.1082\n",
      "Epoch 7/85\n",
      "268/268 [==============================] - 0s 284us/sample - loss: 2.7788 - acc: 0.1791\n",
      "Epoch 8/85\n",
      "268/268 [==============================] - 0s 358us/sample - loss: 2.1936 - acc: 0.2052\n",
      "Epoch 9/85\n",
      "268/268 [==============================] - 0s 328us/sample - loss: 1.8344 - acc: 0.3209\n",
      "Epoch 10/85\n",
      "268/268 [==============================] - 0s 254us/sample - loss: 1.6366 - acc: 0.3881\n",
      "Epoch 11/85\n",
      "268/268 [==============================] - 0s 298us/sample - loss: 1.5336 - acc: 0.4067\n",
      "Epoch 12/85\n",
      "268/268 [==============================] - 0s 269us/sample - loss: 1.4595 - acc: 0.4291\n",
      "Epoch 13/85\n",
      "268/268 [==============================] - 0s 224us/sample - loss: 1.3987 - acc: 0.4328\n",
      "Epoch 14/85\n",
      "268/268 [==============================] - 0s 254us/sample - loss: 1.3382 - acc: 0.4590\n",
      "Epoch 15/85\n",
      "268/268 [==============================] - 0s 328us/sample - loss: 1.2810 - acc: 0.4851\n",
      "Epoch 16/85\n",
      "268/268 [==============================] - 0s 373us/sample - loss: 1.2290 - acc: 0.5149\n",
      "Epoch 17/85\n",
      "268/268 [==============================] - 0s 239us/sample - loss: 1.1763 - acc: 0.5373\n",
      "Epoch 18/85\n",
      "268/268 [==============================] - 0s 269us/sample - loss: 1.1320 - acc: 0.5634\n",
      "Epoch 19/85\n",
      "268/268 [==============================] - 0s 284us/sample - loss: 1.0909 - acc: 0.5970\n",
      "Epoch 20/85\n",
      "268/268 [==============================] - 0s 239us/sample - loss: 1.0526 - acc: 0.6343\n",
      "Epoch 21/85\n",
      "268/268 [==============================] - 0s 373us/sample - loss: 1.0175 - acc: 0.6455\n",
      "Epoch 22/85\n",
      "268/268 [==============================] - 0s 224us/sample - loss: 0.9822 - acc: 0.6828\n",
      "Epoch 23/85\n",
      "268/268 [==============================] - 0s 269us/sample - loss: 0.9470 - acc: 0.6940\n",
      "Epoch 24/85\n",
      "268/268 [==============================] - 0s 373us/sample - loss: 0.9098 - acc: 0.7201\n",
      "Epoch 25/85\n",
      "268/268 [==============================] - 0s 224us/sample - loss: 0.8666 - acc: 0.7313\n",
      "Epoch 26/85\n",
      "268/268 [==============================] - 0s 313us/sample - loss: 0.8195 - acc: 0.7164\n",
      "Epoch 27/85\n",
      "268/268 [==============================] - 0s 343us/sample - loss: 0.7434 - acc: 0.7761\n",
      "Epoch 28/85\n",
      "268/268 [==============================] - 0s 284us/sample - loss: 0.6925 - acc: 0.8022\n",
      "Epoch 29/85\n",
      "268/268 [==============================] - 0s 358us/sample - loss: 0.6496 - acc: 0.8172\n",
      "Epoch 30/85\n",
      "268/268 [==============================] - 0s 298us/sample - loss: 0.6103 - acc: 0.8396\n",
      "Epoch 31/85\n",
      "268/268 [==============================] - 0s 388us/sample - loss: 0.5793 - acc: 0.8507\n",
      "Epoch 32/85\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 0.5521 - acc: 0.8619\n",
      "Epoch 33/85\n",
      "268/268 [==============================] - 0s 284us/sample - loss: 0.5270 - acc: 0.8545\n",
      "Epoch 34/85\n",
      "268/268 [==============================] - 0s 239us/sample - loss: 0.5036 - acc: 0.8694\n",
      "Epoch 35/85\n",
      "268/268 [==============================] - 0s 224us/sample - loss: 0.4741 - acc: 0.8918\n",
      "Epoch 36/85\n",
      "268/268 [==============================] - 0s 269us/sample - loss: 0.4579 - acc: 0.8731\n",
      "Epoch 37/85\n",
      "268/268 [==============================] - 0s 254us/sample - loss: 0.4424 - acc: 0.8806\n",
      "Epoch 38/85\n",
      "268/268 [==============================] - 0s 239us/sample - loss: 0.4148 - acc: 0.9104\n",
      "Epoch 39/85\n",
      "268/268 [==============================] - 0s 269us/sample - loss: 0.3990 - acc: 0.9142\n",
      "Epoch 40/85\n",
      "268/268 [==============================] - 0s 269us/sample - loss: 0.3828 - acc: 0.9067\n",
      "Epoch 41/85\n",
      "268/268 [==============================] - 0s 239us/sample - loss: 0.3647 - acc: 0.9254\n",
      "Epoch 42/85\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 0.3563 - acc: 0.9366\n",
      "Epoch 43/85\n",
      "268/268 [==============================] - 0s 373us/sample - loss: 0.3369 - acc: 0.9366\n",
      "Epoch 44/85\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 0.3246 - acc: 0.9403\n",
      "Epoch 45/85\n",
      "268/268 [==============================] - 0s 269us/sample - loss: 0.3135 - acc: 0.9440\n",
      "Epoch 46/85\n",
      "268/268 [==============================] - ETA: 0s - loss: 0.3157 - acc: 0.950 - 0s 313us/sample - loss: 0.3004 - acc: 0.9515\n",
      "Epoch 47/85\n",
      "268/268 [==============================] - 0s 284us/sample - loss: 0.2936 - acc: 0.9478\n",
      "Epoch 48/85\n",
      "268/268 [==============================] - 0s 284us/sample - loss: 0.2784 - acc: 0.9515\n",
      "Epoch 49/85\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 0.2689 - acc: 0.9590\n",
      "Epoch 50/85\n",
      "268/268 [==============================] - 0s 298us/sample - loss: 0.2608 - acc: 0.9552\n",
      "Epoch 51/85\n",
      "268/268 [==============================] - 0s 254us/sample - loss: 0.2517 - acc: 0.9627\n",
      "Epoch 52/85\n",
      "268/268 [==============================] - 0s 343us/sample - loss: 0.2405 - acc: 0.9664\n",
      "Epoch 53/85\n",
      "268/268 [==============================] - 0s 283us/sample - loss: 0.2328 - acc: 0.9664\n",
      "Epoch 54/85\n",
      "268/268 [==============================] - 0s 239us/sample - loss: 0.2242 - acc: 0.9701\n",
      "Epoch 55/85\n",
      "268/268 [==============================] - 0s 328us/sample - loss: 0.2162 - acc: 0.9739\n",
      "Epoch 56/85\n",
      "268/268 [==============================] - 0s 284us/sample - loss: 0.2115 - acc: 0.9701\n",
      "Epoch 57/85\n",
      "268/268 [==============================] - 0s 298us/sample - loss: 0.2029 - acc: 0.9701\n",
      "Epoch 58/85\n",
      "268/268 [==============================] - 0s 269us/sample - loss: 0.1947 - acc: 0.9813\n",
      "Epoch 59/85\n",
      "268/268 [==============================] - 0s 239us/sample - loss: 0.1882 - acc: 0.9851\n",
      "Epoch 60/85\n",
      "268/268 [==============================] - 0s 239us/sample - loss: 0.1820 - acc: 0.9851\n",
      "Epoch 61/85\n",
      "268/268 [==============================] - 0s 239us/sample - loss: 0.1769 - acc: 0.9813\n",
      "Epoch 62/85\n",
      "268/268 [==============================] - 0s 194us/sample - loss: 0.1700 - acc: 0.9888\n",
      "Epoch 63/85\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 0.1642 - acc: 0.9888\n",
      "Epoch 64/85\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 0.1611 - acc: 0.9888\n",
      "Epoch 65/85\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 0.1548 - acc: 0.9888\n",
      "Epoch 66/85\n",
      "268/268 [==============================] - 0s 239us/sample - loss: 0.1498 - acc: 0.9888\n",
      "Epoch 67/85\n",
      "268/268 [==============================] - 0s 224us/sample - loss: 0.1455 - acc: 0.9925\n",
      "Epoch 68/85\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 0.1400 - acc: 0.9925\n",
      "Epoch 69/85\n",
      "268/268 [==============================] - 0s 224us/sample - loss: 0.1361 - acc: 0.9963\n",
      "Epoch 70/85\n",
      "268/268 [==============================] - 0s 254us/sample - loss: 0.1316 - acc: 0.9963\n",
      "Epoch 71/85\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 0.1275 - acc: 0.9963\n",
      "Epoch 72/85\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 0.1241 - acc: 0.9963\n",
      "Epoch 73/85\n",
      "268/268 [==============================] - 0s 224us/sample - loss: 0.1216 - acc: 0.9925\n",
      "Epoch 74/85\n",
      "268/268 [==============================] - 0s 224us/sample - loss: 0.1172 - acc: 1.0000\n",
      "Epoch 75/85\n",
      "268/268 [==============================] - 0s 194us/sample - loss: 0.1140 - acc: 1.0000\n",
      "Epoch 76/85\n",
      "268/268 [==============================] - 0s 254us/sample - loss: 0.1139 - acc: 0.9925\n",
      "Epoch 77/85\n",
      "268/268 [==============================] - 0s 239us/sample - loss: 0.1064 - acc: 1.0000\n",
      "Epoch 78/85\n",
      "268/268 [==============================] - 0s 284us/sample - loss: 0.1040 - acc: 0.9963\n",
      "Epoch 79/85\n",
      "268/268 [==============================] - 0s 209us/sample - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 80/85\n",
      "268/268 [==============================] - 0s 224us/sample - loss: 0.0987 - acc: 1.0000\n",
      "Epoch 81/85\n",
      "268/268 [==============================] - 0s 298us/sample - loss: 0.0956 - acc: 1.0000\n",
      "Epoch 82/85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 239us/sample - loss: 0.0937 - acc: 1.0000\n",
      "Epoch 83/85\n",
      "268/268 [==============================] - 0s 298us/sample - loss: 0.0905 - acc: 1.0000\n",
      "Epoch 84/85\n",
      "268/268 [==============================] - 0s 269us/sample - loss: 0.0887 - acc: 1.0000\n",
      "Epoch 85/85\n",
      "268/268 [==============================] - 0s 284us/sample - loss: 0.0850 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25e96160e48>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, train_labels, epochs=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 2ms/sample - loss: 0.0833 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(train_dataset, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 267us/sample - loss: 0.1129 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "final_results = model.evaluate(test_dataset, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Naive Bayes </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "modelB = GaussianNB().fit(train_dataset, train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = modelB.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score = accuracy_score(test_labels, predicted_label) \n",
    "print (accuracy_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
