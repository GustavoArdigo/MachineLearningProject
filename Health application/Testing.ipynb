{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Preprocessing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = pd.read_csv(\"Dermatology.csv\", na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_dataset.dropna()\n",
    "dataset.reset_index(drop=True, inplace=True) #reorder rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>erythema</th>\n",
       "      <th>scaling</th>\n",
       "      <th>definiteBorders</th>\n",
       "      <th>itching</th>\n",
       "      <th>koebnerPhenomenon</th>\n",
       "      <th>polygonalPapules</th>\n",
       "      <th>follicularPapules</th>\n",
       "      <th>oralMucosal</th>\n",
       "      <th>kneeElbow</th>\n",
       "      <th>scalp</th>\n",
       "      <th>...</th>\n",
       "      <th>disappearance</th>\n",
       "      <th>vacuolisation</th>\n",
       "      <th>spongiosis</th>\n",
       "      <th>sawTooth</th>\n",
       "      <th>follicularPlug</th>\n",
       "      <th>perifollicular</th>\n",
       "      <th>mononuclear</th>\n",
       "      <th>bandLike</th>\n",
       "      <th>age</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     erythema  scaling  definiteBorders  itching  koebnerPhenomenon  \\\n",
       "353         2        1                1        0                  1   \n",
       "354         3        2                1        0                  1   \n",
       "355         3        2                2        2                  3   \n",
       "356         2        1                3        1                  2   \n",
       "357         3        2                2        0                  0   \n",
       "\n",
       "     polygonalPapules  follicularPapules  oralMucosal  kneeElbow  scalp  ...  \\\n",
       "353                 0                  0            0          0      0  ...   \n",
       "354                 0                  0            0          0      0  ...   \n",
       "355                 2                  0            2          0      0  ...   \n",
       "356                 3                  0            2          0      0  ...   \n",
       "357                 0                  0            0          3      3  ...   \n",
       "\n",
       "     disappearance  vacuolisation  spongiosis  sawTooth  follicularPlug  \\\n",
       "353              0              0           1         0               0   \n",
       "354              1              0           1         0               0   \n",
       "355              0              3           0         3               0   \n",
       "356              0              2           0         1               0   \n",
       "357              2              0           0         0               0   \n",
       "\n",
       "     perifollicular  mononuclear  bandLike   age  disease  \n",
       "353               0            2         0  25.0        4  \n",
       "354               0            2         0  36.0        4  \n",
       "355               0            2         3  28.0        3  \n",
       "356               0            2         3  50.0        3  \n",
       "357               0            3         0  35.0        1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail() #if you want to print everything, just type 'dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Artificial Neural Network </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __future__ #for future features in newer versions\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.75,random_state=0) #that's the seed for the randomization \n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The label is the value we want to predict (in this case, we want to predict the disease): </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.pop('disease')\n",
    "test_labels = test_dataset.pop('disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#34 features + 1 (disease)\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(len(train_dataset.keys())), #input_shape = 34\n",
    "        layers.Dense(16, activation = 'relu'),\n",
    "        layers.Dense(8, activation = 'relu'),\n",
    "        layers.Dense(7, activation = 'softmax'), #6 possible diseases\n",
    "    ])\n",
    "\n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['acc']) \n",
    "    #sparse is used here because our target values are not one-hot-enconded, but integers\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 16)                560       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 7)                 63        \n",
      "=================================================================\n",
      "Total params: 759\n",
      "Trainable params: 759\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "print(model.summary())\n",
    "\n",
    "#params = atual *(anterior +1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Now we have to see if the model training shows decreasing loss and any improvement in accuracy (acc): </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/85\n",
      "268/268 [==============================] - 0s 561us/sample - loss: 7.1800 - acc: 0.1418\n",
      "Epoch 2/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 5.7805 - acc: 0.1604\n",
      "Epoch 3/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 4.7012 - acc: 0.2239\n",
      "Epoch 4/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 3.9065 - acc: 0.3060\n",
      "Epoch 5/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 3.2600 - acc: 0.3470\n",
      "Epoch 6/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 2.6839 - acc: 0.4067\n",
      "Epoch 7/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 2.1783 - acc: 0.4627\n",
      "Epoch 8/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 1.7946 - acc: 0.4813\n",
      "Epoch 9/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 1.5340 - acc: 0.5112\n",
      "Epoch 10/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 1.3843 - acc: 0.5597\n",
      "Epoch 11/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 1.2418 - acc: 0.6231\n",
      "Epoch 12/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 1.1225 - acc: 0.6791\n",
      "Epoch 13/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 1.0218 - acc: 0.7052\n",
      "Epoch 14/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.9297 - acc: 0.7388\n",
      "Epoch 15/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.8372 - acc: 0.7724\n",
      "Epoch 16/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.7629 - acc: 0.7910\n",
      "Epoch 17/85\n",
      "268/268 [==============================] - 0s 89us/sample - loss: 0.6963 - acc: 0.7985\n",
      "Epoch 18/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.6426 - acc: 0.7985\n",
      "Epoch 19/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.5917 - acc: 0.8284\n",
      "Epoch 20/85\n",
      "268/268 [==============================] - 0s 89us/sample - loss: 0.5489 - acc: 0.8545\n",
      "Epoch 21/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.5089 - acc: 0.8657\n",
      "Epoch 22/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.4748 - acc: 0.8955\n",
      "Epoch 23/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.4442 - acc: 0.8955\n",
      "Epoch 24/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.4185 - acc: 0.9142\n",
      "Epoch 25/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.3946 - acc: 0.9142\n",
      "Epoch 26/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.3728 - acc: 0.9104\n",
      "Epoch 27/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.3558 - acc: 0.9179\n",
      "Epoch 28/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.3363 - acc: 0.9216\n",
      "Epoch 29/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.3206 - acc: 0.9216\n",
      "Epoch 30/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.3067 - acc: 0.9254\n",
      "Epoch 31/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.2938 - acc: 0.9328\n",
      "Epoch 32/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.2796 - acc: 0.9403\n",
      "Epoch 33/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.2664 - acc: 0.9440\n",
      "Epoch 34/85\n",
      "268/268 [==============================] - 0s 89us/sample - loss: 0.2562 - acc: 0.9478\n",
      "Epoch 35/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.2454 - acc: 0.9515\n",
      "Epoch 36/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.2365 - acc: 0.9440\n",
      "Epoch 37/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.2268 - acc: 0.9515\n",
      "Epoch 38/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.2168 - acc: 0.9552\n",
      "Epoch 39/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.2091 - acc: 0.9515\n",
      "Epoch 40/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.2004 - acc: 0.9590\n",
      "Epoch 41/85\n",
      "268/268 [==============================] - 0s 89us/sample - loss: 0.1942 - acc: 0.9627\n",
      "Epoch 42/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.1886 - acc: 0.9552\n",
      "Epoch 43/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.1777 - acc: 0.9664\n",
      "Epoch 44/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.1711 - acc: 0.9701\n",
      "Epoch 45/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.1648 - acc: 0.9701\n",
      "Epoch 46/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.1579 - acc: 0.9776\n",
      "Epoch 47/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.1524 - acc: 0.9776\n",
      "Epoch 48/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.1489 - acc: 0.9701\n",
      "Epoch 49/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1403 - acc: 0.9776\n",
      "Epoch 50/85\n",
      "268/268 [==============================] - 0s 89us/sample - loss: 0.1379 - acc: 0.9739\n",
      "Epoch 51/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.1336 - acc: 0.9776\n",
      "Epoch 52/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1280 - acc: 0.9776\n",
      "Epoch 53/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1245 - acc: 0.9776\n",
      "Epoch 54/85\n",
      "268/268 [==============================] - 0s 119us/sample - loss: 0.1193 - acc: 0.9813\n",
      "Epoch 55/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.1162 - acc: 0.9776\n",
      "Epoch 56/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.1126 - acc: 0.9813\n",
      "Epoch 57/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1101 - acc: 0.9776\n",
      "Epoch 58/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.1107 - acc: 0.9701\n",
      "Epoch 59/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1045 - acc: 0.9776\n",
      "Epoch 60/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.1010 - acc: 0.9776\n",
      "Epoch 61/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0962 - acc: 0.9776\n",
      "Epoch 62/85\n",
      "268/268 [==============================] - 0s 90us/sample - loss: 0.0932 - acc: 0.9776\n",
      "Epoch 63/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.0907 - acc: 0.9813\n",
      "Epoch 64/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.0884 - acc: 0.9776\n",
      "Epoch 65/85\n",
      "268/268 [==============================] - 0s 89us/sample - loss: 0.0867 - acc: 0.9776\n",
      "Epoch 66/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0829 - acc: 0.9813\n",
      "Epoch 67/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0808 - acc: 0.9776\n",
      "Epoch 68/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0775 - acc: 0.9776\n",
      "Epoch 69/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0768 - acc: 0.9813\n",
      "Epoch 70/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0734 - acc: 0.9776\n",
      "Epoch 71/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0742 - acc: 0.9776\n",
      "Epoch 72/85\n",
      "268/268 [==============================] - 0s 119us/sample - loss: 0.0706 - acc: 0.9776\n",
      "Epoch 73/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0686 - acc: 0.9813\n",
      "Epoch 74/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0679 - acc: 0.9888\n",
      "Epoch 75/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0656 - acc: 0.9776\n",
      "Epoch 76/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.0649 - acc: 0.9776\n",
      "Epoch 77/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0631 - acc: 0.9851\n",
      "Epoch 78/85\n",
      "268/268 [==============================] - 0s 89us/sample - loss: 0.0643 - acc: 0.9776\n",
      "Epoch 79/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0627 - acc: 0.9813\n",
      "Epoch 80/85\n",
      "268/268 [==============================] - 0s 75us/sample - loss: 0.0587 - acc: 0.9888\n",
      "Epoch 81/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.0582 - acc: 0.9813\n",
      "Epoch 82/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.0566 - acc: 0.9851\n",
      "Epoch 83/85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 60us/sample - loss: 0.0560 - acc: 0.9813\n",
      "Epoch 84/85\n",
      "268/268 [==============================] - 0s 104us/sample - loss: 0.0535 - acc: 0.9851\n",
      "Epoch 85/85\n",
      "268/268 [==============================] - 0s 60us/sample - loss: 0.0540 - acc: 0.9888\n"
     ]
    }
   ],
   "source": [
    "predicted_labels_ANN = model.fit(train_dataset, train_labels, epochs=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.plot(predicted_labels_ANN.history['acc'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 [==============================] - 0s 269us/sample - loss: 0.2077 - acc: 0.9813\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(train_dataset, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 44us/sample - loss: 0.2572 - acc: 0.9667\n"
     ]
    }
   ],
   "source": [
    "final_results = model.evaluate(test_dataset, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Naive Bayes </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Let's test the Gaussian Naive Bayes approach: </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "modelB = GaussianNB().fit(train_dataset, train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = modelB.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score = accuracy_score(test_labels, predicted_label) \n",
    "print (accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Metrics </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function to display dataframes for a better analysis\n",
    "#https://stackoverflow.com/questions/38783027/jupyter-notebook-display-two-pandas-tables-side-by-side\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def display_side_by_side(dfs:list, captions:list):\n",
    "    \"\"\"Display tables side by side to save vertical space\n",
    "    Input:\n",
    "        dfs: list of pandas.DataFrame\n",
    "        captions: list of table captions\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    combined = dict(zip(captions, dfs))\n",
    "    for caption, df in combined.items():\n",
    "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += \"\\xa0\\xa0\\xa0\"\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abb\" style='display:inline'><caption>ANN</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >1</th>        <th class=\"col_heading level0 col1\" >2</th>        <th class=\"col_heading level0 col2\" >3</th>        <th class=\"col_heading level0 col3\" >4</th>        <th class=\"col_heading level0 col4\" >5</th>        <th class=\"col_heading level0 col5\" >6</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abblevel0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow0_col0\" class=\"data row0 col0\" >35</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow0_col1\" class=\"data row0 col1\" >1</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow0_col2\" class=\"data row0 col2\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow0_col3\" class=\"data row0 col3\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow0_col4\" class=\"data row0 col4\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow0_col5\" class=\"data row0 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abblevel0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow1_col0\" class=\"data row1 col0\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow1_col1\" class=\"data row1 col1\" >10</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow1_col2\" class=\"data row1 col2\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow1_col3\" class=\"data row1 col3\" >2</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow1_col4\" class=\"data row1 col4\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow1_col5\" class=\"data row1 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abblevel0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow2_col0\" class=\"data row2 col0\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow2_col1\" class=\"data row2 col1\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow2_col2\" class=\"data row2 col2\" >14</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow2_col3\" class=\"data row2 col3\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow2_col4\" class=\"data row2 col4\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow2_col5\" class=\"data row2 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abblevel0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow3_col0\" class=\"data row3 col0\" >1</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow3_col1\" class=\"data row3 col1\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow3_col2\" class=\"data row3 col2\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow3_col3\" class=\"data row3 col3\" >13</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow3_col4\" class=\"data row3 col4\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow3_col5\" class=\"data row3 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abblevel0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow4_col0\" class=\"data row4 col0\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow4_col1\" class=\"data row4 col1\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow4_col2\" class=\"data row4 col2\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow4_col3\" class=\"data row4 col3\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow4_col4\" class=\"data row4 col4\" >12</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow4_col5\" class=\"data row4 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abblevel0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow5_col0\" class=\"data row5 col0\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow5_col1\" class=\"data row5 col1\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow5_col2\" class=\"data row5 col2\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow5_col3\" class=\"data row5 col3\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow5_col4\" class=\"data row5 col4\" >0</td>\n",
       "                        <td id=\"T_1e01a438_d94e_11e9_bec5_a402b9003abbrow5_col5\" class=\"data row5 col5\" >2</td>\n",
       "            </tr>\n",
       "    </tbody></table>   <style  type=\"text/css\" >\n",
       "</style><table id=\"T_1e024062_d94e_11e9_be99_a402b9003abb\" style='display:inline'><caption>GNB</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >1</th>        <th class=\"col_heading level0 col1\" >2</th>        <th class=\"col_heading level0 col2\" >3</th>        <th class=\"col_heading level0 col3\" >4</th>        <th class=\"col_heading level0 col4\" >5</th>        <th class=\"col_heading level0 col5\" >6</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_1e024062_d94e_11e9_be99_a402b9003abblevel0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow0_col0\" class=\"data row0 col0\" >36</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow0_col1\" class=\"data row0 col1\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow0_col2\" class=\"data row0 col2\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow0_col3\" class=\"data row0 col3\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow0_col4\" class=\"data row0 col4\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow0_col5\" class=\"data row0 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1e024062_d94e_11e9_be99_a402b9003abblevel0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow1_col0\" class=\"data row1 col0\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow1_col1\" class=\"data row1 col1\" >5</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow1_col2\" class=\"data row1 col2\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow1_col3\" class=\"data row1 col3\" >6</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow1_col4\" class=\"data row1 col4\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow1_col5\" class=\"data row1 col5\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1e024062_d94e_11e9_be99_a402b9003abblevel0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow2_col0\" class=\"data row2 col0\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow2_col1\" class=\"data row2 col1\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow2_col2\" class=\"data row2 col2\" >14</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow2_col3\" class=\"data row2 col3\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow2_col4\" class=\"data row2 col4\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow2_col5\" class=\"data row2 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1e024062_d94e_11e9_be99_a402b9003abblevel0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow3_col0\" class=\"data row3 col0\" >1</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow3_col1\" class=\"data row3 col1\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow3_col2\" class=\"data row3 col2\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow3_col3\" class=\"data row3 col3\" >13</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow3_col4\" class=\"data row3 col4\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow3_col5\" class=\"data row3 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1e024062_d94e_11e9_be99_a402b9003abblevel0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow4_col0\" class=\"data row4 col0\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow4_col1\" class=\"data row4 col1\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow4_col2\" class=\"data row4 col2\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow4_col3\" class=\"data row4 col3\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow4_col4\" class=\"data row4 col4\" >12</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow4_col5\" class=\"data row4 col5\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1e024062_d94e_11e9_be99_a402b9003abblevel0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow5_col0\" class=\"data row5 col0\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow5_col1\" class=\"data row5 col1\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow5_col2\" class=\"data row5 col2\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow5_col3\" class=\"data row5 col3\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow5_col4\" class=\"data row5 col4\" >0</td>\n",
       "                        <td id=\"T_1e024062_d94e_11e9_be99_a402b9003abbrow5_col5\" class=\"data row5 col5\" >2</td>\n",
       "            </tr>\n",
       "    </tbody></table>   "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction_ANN = model.predict(test_dataset) #shows the probabilities for each disease given one row\n",
    "predictions_ANN = np.argmax(prediction_ANN, axis = 1) #the highest probability value is taken by the disease for that row\n",
    "\n",
    "labels = list(set(test_labels))\n",
    "df_ANN = pd.DataFrame(\n",
    "    data = confusion_matrix(test_labels, predictions_ANN, labels=labels),\n",
    "    columns=labels,\n",
    "    index=labels\n",
    ")\n",
    "\n",
    "\n",
    "df_GNB = pd.DataFrame(\n",
    "    data  = confusion_matrix(test_labels, predicted_label, labels=labels),\n",
    "    columns=labels,\n",
    "    index=labels\n",
    ")\n",
    "\n",
    "display_side_by_side([df_ANN, df_GNB], ['ANN', 'GNB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9722    0.9722    0.9722        36\n",
      "           2     0.9091    0.8333    0.8696        12\n",
      "           3     1.0000    1.0000    1.0000        14\n",
      "           4     0.8667    0.9286    0.8966        14\n",
      "           5     1.0000    1.0000    1.0000        12\n",
      "           6     1.0000    1.0000    1.0000         2\n",
      "\n",
      "    accuracy                         0.9556        90\n",
      "   macro avg     0.9580    0.9557    0.9564        90\n",
      "weighted avg     0.9560    0.9556    0.9554        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9730    1.0000    0.9863        36\n",
      "           2     1.0000    0.4167    0.5882        12\n",
      "           3     1.0000    1.0000    1.0000        14\n",
      "           4     0.6842    0.9286    0.7879        14\n",
      "           5     1.0000    1.0000    1.0000        12\n",
      "           6     0.6667    1.0000    0.8000         2\n",
      "\n",
      "    accuracy                         0.9111        90\n",
      "   macro avg     0.8873    0.8909    0.8604        90\n",
      "weighted avg     0.9327    0.9111    0.9022        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, predictions_ANN, digits=4))\n",
    "print(classification_report(test_labels, predicted_label, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
